<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Solar Panel Anomaly Classification using SARNet Model | Grace Ugochi Nneji</title>
  <link rel="stylesheet" href="https://graceugochinneji.github.io/css/semantic.min.css">
  <style>
    .project-header {
      text-align: center;
      background-color: #e67e22;
      color: #fff;
      padding: 20px;
      font-size: 2em;
    }
    .content-section {
      max-width: 800px;
      margin: 20px auto;
      padding: 20px;
      line-height: 1.6;
      color: #333;
    }
    .button-group {
      text-align: center;
      margin: 20px 0;
    }
    .button-group a {
      padding: 10px 20px;
      margin: 5px;
      background-color: #e67e22;
      color: #fff;
      border-radius: 5px;
      text-decoration: none;
      transition: background-color 0.3s;
    }
    .button-group a:hover {
      background-color: #d35400;
    }
  </style>
</head>
<body>

<div class="project-header">
  Solar Panel Anomaly Classification using SARNet Model
</div>

<div class="content-section">
  <h2>What is this project about?</h2>
  <p>This project by Sienna introduces SARNet, a hybrid deep learning framework for detecting defects in photovoltaic solar panels using infrared and electroluminescence (EL) images. SARNet integrates StackNet for hierarchical feature extraction, ResoNet for multi-scale pattern recognition, and SE attention for adaptive feature refinement.</p>

  <div class="button-group">
    <a href="https://github.com/RaptorMaps/InfraredSolarModules" target="_blank">Infrared Solar Modules Dataset</a>
    <a href="https://github.com/zae-bayern/elpv-dataset" target="_blank">ELPV Dataset</a>
    <a href="https://graceugochinneji.github.io/Poster/Sienna_Poster.pdf" download>Download Poster</a>
  </div>

  <h2>How was the SARNet Model designed and implemented?</h2>
  <p>
    This project introduces <strong>SARNet</strong>, a hybrid deep learning model tailored for detecting solar panel defects in both infrared and electroluminescence (EL) images. SARNet builds upon the following architectural innovations:
  </p>

  <ul>
    <li><strong>StackNet Backbone:</strong> Built on a modified ResNet-18, StackNet introduces wide-kernel convolutions and optimized residual blocks for efficient low-level feature extraction. It incrementally increases channel depth across four stages (64 to 512) while maintaining spatial resolution through stride adjustments and shortcut connections to mitigate vanishing gradients.</li>
    <li><strong>ResoNet Module:</strong> A resolution-aware block integrated within StackNet’s residual structure. Inspired by the Inception design, it uses four parallel branches targeting small, medium, and large receptive fields. This allows it to handle subtle faults like cracking and vegetation by capturing diverse feature scales simultaneously.</li>
    <li><strong>Squeeze-and-Excitation (SE) Attention Mechanism:</strong> Applied after ResoNet, this module enhances the most informative channels using global average pooling and fully connected layers. It adaptively emphasizes critical features for defect detection while suppressing irrelevant noise, improving discriminative focus across image modalities.</li>
  </ul>

  <h3>Data Preprocessing and Augmentation</h3>
  <ul>
    <li>Images from both datasets were resized to <strong>224×224 pixels</strong>.</li>
    <li>Data augmentation included: horizontal flipping, rotation (±10–20%), zoom, shear, and width-height shifts to increase diversity and reduce overfitting.</li>
    <li>For Dataset 1 (six-class task), hybrid resampling balanced classes to 1,000 samples each using both oversampling and undersampling. Dataset 2 (binary) merged two similar classes to simplify classification.</li>
  </ul>

  <h3>Training Setup</h3>
  <ul>
    <li><strong>Optimizer:</strong> Adam</li>
    <li><strong>Learning Rate:</strong> 0.001 (reduced on plateau)</li>
    <li><strong>Epochs:</strong> 100</li>
    <li><strong>Batch Size:</strong> 438 (binary), 29 (six-class), and 24 (ELPV dataset)</li>
    <li><strong>Callbacks:</strong> Learning rate decay, early stopping, and checkpointing</li>
  </ul>

  <h3>Experimental Results</h3>
  <p><strong>SARNet achieved state-of-the-art results:</strong></p>
  <ul>
    <li>On Dataset 1 (2-Class): Accuracy = 91.7%, F1 = 0.914, PR-AUC = 0.973</li>
    <li>On Dataset 1 (6-Class): Accuracy = 81.63%, F1 = 0.816, ROC-AUC (Diode) = 1.0</li>
    <li>On Dataset 2 (2-Class): Accuracy = 89.1%, F1 = 0.872, ROC-AUC = 0.93</li>
  </ul>

  <h3>Model Evaluation and Insight</h3>
  <p>
    Compared to StackNet and SRNet, SARNet showed significant improvements in handling overlapping, subtle, and multi-scale anomalies. Precision-Recall curves and confusion matrices confirm strong generalization and low misclassification on unseen data.
  </p>

  <h2>Conclusion</h2>
  <p>
    SARNet, by combining multi-scale feature extraction (ResoNet), structural reuse (StackNet), and attention-driven refinement (SE), proves to be an effective deep learning solution for defect detection in solar modules, offering high accuracy, robustness, and generalization across datasets and tasks.
  </p>

  <h2>Limitations</h2>
  <ul>
    <li>Model is trained on only two datasets, which may not cover real-world edge cases.</li>
    <li>Performance may be affected by variation in image quality and panel types.</li>
    <li>No real-time deployment or integration with drone/UAV platforms was tested.</li>
  </ul>

  <h2>Future Work</h2>
  <ul>
    <li>Extend SARNet to integrate temporal infrared video data for dynamic inspection.</li>
    <li>Deploy SARNet on mobile or embedded devices for real-time field applications.</li>
    <li>Fuse image data with temperature, voltage, or current readings for multimodal defect diagnosis.</li>
  </ul>
</div>

<script src="https://graceugochinneji.github.io/css/semantic.min.js"></script>
</body>
</html>
