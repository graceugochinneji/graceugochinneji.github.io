<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Siamese Network for Dog-Breed Recognition | Wentian Shen</title>

  <!-- =====  PALETTE  (cream ➜ plum)  ===== -->
  <style>
    :root{
      --bg-start:#fffdf5;      /* light cream      */
      --bg-end:  #f6f0ff;      /* faint lavender   */
      --brand-main:#c17ff0;    /* soft plum        */
      --brand-accent:#6452d0;  /* muted indigo     */
      --text-main:#333;
      --card-bg:#ffffff;
    }

    body{
      font-family:'Segoe UI',Tahoma,Geneva,Verdana,sans-serif;
      background:linear-gradient(to right,var(--bg-start),var(--bg-end));
      color:var(--text-main);margin:0;padding:0;
    }
    header,section{
      padding:20px;margin:20px;border-radius:12px;
      background:var(--card-bg);
      box-shadow:0 4px 8px rgba(0,0,0,.1);
    }
    header{
      background:linear-gradient(to right,var(--brand-main),var(--brand-accent));
      color:#fff;text-align:center;
    }
    h1{margin:0;padding:10px 0;line-height:1.3;}
    h2{color:#00796b;margin-top:0.5rem;}
    ul{padding-left:20px;}
    li{margin-bottom:8px;}

    /* buttons */
    .button-group{text-align:center;margin:20px 0;}
    .button-group a{
      display:inline-block;padding:10px 22px;margin:4px;
      background:var(--brand-main);color:#fff;border-radius:5px;
      text-decoration:none;transition:opacity .25s ease;
    }
    .button-group a:nth-child(3){background:var(--brand-accent);}  /* poster */
    .button-group a:hover{opacity:.88;}

    /* footer */
    footer{
      text-align:center;padding:15px;color:#fff;
      background:var(--brand-main);font-size:.9em;margin-top:40px;
    }
  </style>
</head>
<body>

<header>
  <h1>Recognition of Dog Breed<br>Using a Siamese CNN</h1>
</header>

<section>
  <h2>Project Overview</h2>
  <p>
    Wentian Shen designs a dual-branch <strong>Siamese neural network</strong> that compares
    feature embeddings from twin <em>ResNet-50&nbsp;v2</em> backbones to decide whether two
    dog photos belong to the same breed.  Tested on a 20-breed subset of the Stanford
    Dogs data, the system reaches <strong>78 % accuracy</strong> in one-shot breed identification,
    demonstrating the viability of metric-learning for fine-grained pet recognition.:contentReference[oaicite:0]{index=0}
  </p>
</section>

<div class="button-group">
  <a href="https://www.kaggle.com/datasets/jessicali9530/stanford-dogs-dataset" target="_blank">Stanford Dogs Dataset</a>
  <a href="https://github.com/username/Siamese-DogBreed" target="_blank">GitHub Repo</a>
  <a href="https://graceugochinneji.github.io/Poster/Desson_Poster.pdf" download>Download Poster</a>
</div>

<section>
  <h2>Key Contributions</h2>
  <ul>
    <li>Built a <strong>Siamese-ResNet-50&nbsp;v2</strong> with shared weights and contrastive loss
        (margin = 1) to learn a breed-similarity metric.:contentReference[oaicite:1]{index=1}</li>
    <li>Curated ten incremental sub-datasets (2 → 20 breeds) to
        analyse the effect of class count on Siamese performance.:contentReference[oaicite:2]{index=2}</li>
    <li>Performed hyper-parameter sweeps (batch = 8, LR = 5 × 10⁻⁴, epoch = 9) that
        maximised validation accuracy without over-fitting.:contentReference[oaicite:3]{index=3}</li>
    <li>Released a <strong>Flask / Tkinter GUI</strong> that outputs similarity scores and visualises the
        decision in &lt; 1 s per image pair.:contentReference[oaicite:4]{index=4}</li>
  </ul>
</section>

<section>
  <h2>Results Snapshot</h2>
  <ul>
    <li><strong>Best accuracy&nbsp;:</strong> 78 % @ 20 breeds</li>
    <li><strong>Loss&nbsp;:</strong> 0.0051 (train) · 1.16 (val)</li>
    <li><strong>Parameter count&nbsp;:</strong> 25.7 M (only 128 k trainable):contentReference[oaicite:5]{index=5}</li>
  </ul>
</section>

<section>
  <h2>Limitations</h2>
  <ul>
    <li>Needs more GPU memory to scale up to the full 120-breed dataset.</li>
    <li>One-shot approach under-performs plain classification CNNs by ~10 pp.:contentReference[oaicite:6]{index=6}</li>
    <li>Confuses visually similar terriers when training data per class is sparse.</li>
  </ul>
</section>

<section>
  <h2>Future Work</h2>
  <ul>
    <li>Distil the Siamese model into a lightweight mobile network for on-device pet apps.</li>
    <li>Incorporate triplet or circle loss to tighten intra-breed clusters.</li>
    <li>Expand training to the full Stanford 120 breeds once higher-memory hardware is available.</li>
  </ul>
</section>

<footer>
  © 2025 Wentian Shen · Siamese Dog-Breed Recognition Project
</footer>

</body>
</html>
