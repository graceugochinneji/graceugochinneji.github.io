<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Early Cancer Detection Project | Grace Ugochi Nneji</title>
  <link rel="stylesheet" href="https://graceugochinneji.github.io/css/semantic.min.css">
  <style>
    .project-header {
      text-align: center;
      background-color: #5cb85c;
      color: #fff;
      padding: 20px;
      font-size: 2em;
    }
    .content-section {
      max-width: 800px;
      margin: 20px auto;
      padding: 20px;
      line-height: 1.6;
      color: #333;
    }
    .button-group {
      text-align: center;
      margin: 20px 0;
    }
    .button-group a {
      padding: 10px 20px;
      margin: 5px;
      background-color: #5cb85c;
      color: #fff;
      border-radius: 5px;
      text-decoration: none;
      transition: background-color 0.3s;
    }
    .button-group a:hover {
      background-color: #4cae4c;
    }
  </style>
</head>
<body>

<div class="project-header">
  Early Cancer Detection Using Multi-Scale CNN and Transformer-Based Deep Learning Approaches
</div>

<div class="content-section">
  <h2>What is this project about?</h2>
  <p>This study introduces a hybrid deep learning model designed to detect early-stage breast cancer from histopathological images. The model integrates EfficientNetV2 for local feature extraction and Vision Transformers (ViTs) for global context analysis, enhanced with Shifted Patch Tokenization (SPT) and Learned-Scale Attention (LSA).</p>

  <div class="button-group">
    <a href="https://www.kaggle.com/datasets/ambarish/breakhis" target="_blank">BreakHis Dataset</a>
    <a href="https://www.kaggle.com/datasets/truthisneverlinear/bach-breast-cancer-histology-images" target="_blank">BACH Dataset</a>
    <a href="/downloads/Carson_Poster.pptx" download>Download Poster</a>
  </div>

  <h2>How was it implemented?</h2>
  <p>The architecture features a dual-branch model:</p>
  <ul>
    <li><strong>EfficientNetV2:</strong> for compact and efficient local spatial feature extraction.</li>
    <li><strong>ViT:</strong> for long-range dependency modeling with SPT and LSA enhancements.</li>
  </ul>
  <p>The model was trained on BreakHis (70/10/20 split) and validated on BACH (80/20 split), both using oversampling for class balance. Image preprocessing included resizing to 160×160, normalization to [0,1], and real-time augmentation.</p>

  <h2>What are the key results?</h2>
  <ul>
    <li><strong>BreakHis:</strong> Accuracy = 92.1%, AUC = 0.9715, Sensitivity = 94.6%</li>
    <li><strong>BACH:</strong> Accuracy = 86.7%, AUC = 0.8700, Sensitivity = 92.5%</li>
  </ul>
  <p>These outcomes highlight the model’s strong generalization and high sensitivity for early cancer detection tasks across datasets.</p>

  <h2>Conclusion & Future Work</h2>
  <p>The hybrid CNN+ViT model demonstrates excellent potential for clinical applications in digital pathology. Limitations include its reliance on single-modality image data and high computational demand. Future efforts will focus on multimodal data integration, lightweight transformer architectures, and enhancing interpretability through attention trajectory visualizations.</p>
</div>

<script src="https://graceugochinneji.github.io/css/semantic.min.js"></script>
</body>
</html>
