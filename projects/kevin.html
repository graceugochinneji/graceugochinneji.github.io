<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Photorealistic Face Synthesis with Enhanced DCGAN | Kevin Yi</title>
  <style>
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      background: linear-gradient(to right, #e0f7fa, #fce4ec);
      color: #333;
      margin: 0;
      padding: 0;
    }
    header, section {
      padding: 20px;
      margin: 20px;
      border-radius: 12px;
      background-color: #ffffff;
      box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    }
    header {
      background: linear-gradient(to right, #00acc1, #ec407a);
      color: white;
      text-align: center;
    }
    h1 {
      margin: 0;
      padding: 10px 0;
    }
    h2 {
      color: #00796b;
    }
    ul {
      padding-left: 20px;
    }
    li {
      margin-bottom: 8px;
    }
    .button-group {
      text-align: center;
      margin: 20px;
    }
    .button-group a {
      padding: 10px 20px;
      margin: 5px;
      background-color: #00acc1;
      color: #fff;
      border-radius: 5px;
      text-decoration: none;
      transition: background-color 0.3s;
    }
    .button-group a:nth-child(3) {
      background-color: #ec407a;   /* poster button tint */
    }
    .button-group a:hover {
      opacity: 0.9;
    }
    footer {
      text-align: center;
      padding: 15px;
      color: #ffffff;
      background-color: #00acc1;
      font-size: 0.9em;
      margin-top: 40px;
    }
  </style>
</head>
<body>
  <header>
    <h1>Photorealistic Face Synthesis with Enhanced DCGAN</h1>
  </header>

  <section>
    <h2>Project Overview</h2>
    <p>
      This work presents an upgraded <em>Deep Convolutional GAN</em> (DCGAN) that synthesises diverse, high-resolution human-face images. Kevin Yi augments the classic DCGAN with
      residual blocks, extensive dropout, and an adaptive learning-rate scheduler to stabilise training and reduce mode collapse. Training is performed on two public face datasets
      and evaluated with Fréchet Inception Distance (FID) and diversity metrics.
    </p>
  </section>

  <div class="button-group">
    <a href="https://www.kaggle.com/datasets/selfishgene/synthetic-faces-high-quality-shq-part-1" target="_blank">Synthetic Faces Dataset</a>
    <a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html" target="_blank">CelebA Dataset</a>
    <a href="https://graceugochinneji.github.io/Poster/Kevin_PPT.pdf" download>Download Poster</a>
  </div>
  
  <section>
    <h2>Key Contributions</h2>
    <ul>
      <li>Designed an <strong>Enhanced DCGAN</strong> with two residual blocks and LeakyReLU activations.</li>
      <li>Applied heavy data augmentation and <em>One-Cycle</em> learning-rate policy for faster convergence.</li>
      <li>Achieved an FID of <strong>21.4</strong> on the SHQ dataset—an 18 % improvement over baseline DCGAN.</li>
      <li>Quantified image diversity using <em>LPIPS</em> and coverage metrics.</li>
      <li>Released a PyTorch-based training pipeline plus inference GUI (Tkinter).</li>
    </ul>
  </section>

  <section>
    <h2>Conclusion</h2>
    <p>
      The residual-augmented DCGAN consistently generates photorealistic, varied faces while maintaining a lightweight footprint (11 M parameters). Results indicate that simple architectural
      tweaks and disciplined regularisation can rival heavier GAN variants on mid-tier GPUs, opening opportunities for embedded or edge deployment.
    </p>
  </section>

  <section>
    <h2>Limitations</h2>
    <ul>
      <li>Trained exclusively on human-face data—performance on other object classes is unverified.</li>
      <li>No explicit bias mitigation: distribution skews in the training set may propagate to the generated images.</li>
      <li>Some minor artefacts persist at very high resolutions (&gt;512×512).</li>
    </ul>
  </section>

  <section>
    <h2>Future Work</h2>
    <ul>
      <li>Introduce <em>StyleGAN-style</em> mapping networks for better attribute control.</li>
      <li>Implement conditional GANs to target age, emotion, or ethnicity on demand.</li>
      <li>Port model to a web demo via TensorFlow.js for real-time browser inference.</li>
    </ul>
  </section>

  <footer>
    <p>© 2025 Kevin Yi. GAN Face-Synthesis Project.</p>
  </footer>
</body>
</html>
