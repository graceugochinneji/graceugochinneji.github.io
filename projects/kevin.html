<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Generative Adversarial Network for Synthetic Image Generation | Kevin Yi</title>

  <!-- Semantic UI (same CDN you’re already using) -->
  <link rel="stylesheet" href="https://graceugochinneji.github.io/css/semantic.min.css">

  <style>
    .project-header {
      text-align: center;
      background-color: #5cb85c;
      color: #fff;
      padding: 20px;
      font-size: 2em;
    }
    .content-section {
      max-width: 800px;
      margin: 20px auto;
      padding: 20px;
      line-height: 1.6;
      color: #333;
    }
    .button-group {
      text-align: center;
      margin: 20px 0;
    }
    .button-group a {
      padding: 10px 20px;
      margin: 5px;
      background-color: #5cb85c;
      color: #fff;
      border-radius: 5px;
      text-decoration: none;
      transition: background-color 0.3s;
    }
    .button-group a:hover {
      background-color: #4cae4c;
    }
  </style>
</head>
<body>

<div class="project-header">
  Generative Adversarial Network for Synthetic Image Generation
</div>

<div class="content-section">
  <h2>What is this project about?</h2>
  <p>
    This undergraduate project explores the use of Generative Adversarial Networks (GANs) to create photorealistic synthetic <em>human-face</em> images. 
    Kevin Yi proposes an enhanced DCGAN architecture that integrates residual blocks, dropout regularisation and LeakyReLU activations to stabilise training and boost image quality.:contentReference[oaicite:0]{index=0}
  </p>

  <div class="button-group">
    <a href="https://www.kaggle.com/datasets/selfishgene/synthetic-faces-high-quality-shq-part-1" target="_blank">Synthetic Faces Dataset</a>
    <a href="https://github.com/KevinYiii/GAN-for-Synthetic-Image-Generation" target="_blank">GitHub Repo</a>
    <a href="https://graceugochinneji.github.io/Poster/Kevin_Poster.pdf" download>Download Poster</a>
  </div>

  <h2>How was it implemented?</h2>
  <p>The generator upsamples a 175-dimensional latent vector through seven transposed-convolution layers <strong>(256&nbsp;×&nbsp;256 output)</strong>, inserting two residual blocks mid-stream to preserve fine details. 
     The discriminator mirrors this depth with six convolutional layers, but its capacity is deliberately curbed (high dropout &amp; smaller LeakyReLU slope) so the generator has room to learn. Training used 2 500 HD face images with heavy augmentation and an adaptive learning-rate scheduler.:contentReference[oaicite:1]{index=1}
  </p>

  <h2>What are the key results?</h2>
  <ul>
    <li><strong>Visual quality:</strong> FID steadily decreased throughout training, indicating the synthetic faces became increasingly indistinguishable from real ones.:contentReference[oaicite:2]{index=2}</li>
    <li><strong>Diversity:</strong> Residual connections prevented mode collapse, enabling wide variation in age, pose and accessories.</li>
    <li><strong>Efficiency:</strong> Final model converged in &lt; 800 epochs on an NVIDIA GTX 1660 Ti GPU.:contentReference[oaicite:3]{index=3}</li>
  </ul>

  <h2>Conclusion &amp; Future Work</h2>
  <p>
    The improved DCGAN demonstrates that lightweight architectural tweaks—residual blocks plus calibrated discriminator regularisation—can yield high-fidelity, diverse face synthesis on limited data. 
    Future directions include conditional GANs for controllable attributes, super-resolution post-processing, and a web demo to replace the current Tkinter GUI.:contentReference[oaicite:4]{index=4}
  </p>
</div>

<script src="https://graceugochinneji.github.io/css/semantic.min.js"></script>
</body>
</html>
