<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Retinal Disease Classification Project | Grace Ugochi Nneji</title>
  <link rel="stylesheet" href="https://graceugochinneji.github.io/css/semantic.min.css">
  <style>
    .project-header {
      text-align: center;
      background-color: #9b59b6;
      color: #fff;
      padding: 20px;
      font-size: 2em;
    }
    .content-section {
      max-width: 800px;
      margin: 20px auto;
      padding: 20px;
      line-height: 1.6;
      color: #333;
    }
    .button-group {
      text-align: center;
      margin: 20px 0;
    }
    .button-group a {
      padding: 10px 20px;
      margin: 5px;
      background-color: #9b59b6;
      color: #fff;
      border-radius: 5px;
      text-decoration: none;
      transition: background-color 0.3s;
    }
    .button-group a:hover {
      background-color: #8e44ad;
    }
  </style>
</head>
<body>

<div class="project-header">
  Supervised Learning for Retinal Disease Classification Using Fundus Images
</div>

<div class="content-section">
  <h2>What is this project about?</h2>
  <p>This project by David presents a supervised deep learning model for classifying diabetic retinopathy severity levels using fundus retinal images. The model integrates convolutional blocks from VGG and ResNet architectures, enhanced by Squeeze-and-Excitation (SE) attention for improved feature recalibration and robust classification performance.</p>

  <div class="button-group">
    <a href="https://www.kaggle.com/c/aptos2019-blindness-detection/data" target="_blank">Download Dataset</a>
    <a href="https://graceugochinneji.github.io/Poster/David_Poster.pdf" download>Download Poster</a>
  </div>

  <h2>How was it implemented?</h2>
  <p>The dataset (APTOS 2019) contains retinal images labeled into five categories based on DR severity. The model applies extensive preprocessing, including resizing, normalization, and augmentation (zoom, brightness, blur, contrast). The hybrid architecture uses VGG blocks for texture and ResNet for structural encoding, with SE attention modules improving focus on discriminative areas.</p>

  <h2>What were the key results?</h2>
  <p>On the test set, the model achieved:</p>
  <ul>
    <li><strong>Accuracy:</strong> 89.80%</li>
    <li><strong>F1 Score:</strong> 0.8988</li>
    <li><strong>Precision & Recall:</strong> ≈ 0.90</li>
  </ul>
  <p>These metrics highlight the model’s effectiveness, particularly in distinguishing normal and severe cases. Performance on moderate DR, however, showed room for improvement due to class imbalance.</p>

  <h2>Conclusion</h2>
  <p>This work proposed a CNN model for diabetic retinopathy (DR) classification that combined VGG and ResNet architectures, along with Squeeze-and-Excitation (SE) attention. Trained on the APTOS 2019 dataset, the model achieved strong generalization with balanced precision and recall. Its architecture is adaptable and interpretable for real-world clinical screening applications.</p>

  <h2>Limitations</h2>
  <ul>
    <li>Class imbalance affected performance for moderate DR cases.</li>
    <li>Model was trained and evaluated on a single dataset, which may limit generalizability.</li>
    <li>Further work is needed to adapt the model to various imaging conditions and populations.</li>
  </ul>

  <h2>Future Work</h2>
  <ul>
    <li>Integrate self-supervised pretraining to reduce reliance on labeled data.</li>
    <li>Improve regularization techniques and learning rate schedules for stability.</li>
    <li>Incorporate Explainable AI (XAI) tools for visual interpretability (e.g., Grad-CAM).</li>
    <li>Expand to other datasets and real-world testing environments.</li>
  </ul>
</div>

<script src="https://graceugochinneji.github.io/css/semantic.min.js"></script>
</body>
</html>
